{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bezAUG_DOBRE_Sieć_CNN_2_klasy_90.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xzYJQwRIpVTb1rRTzqQt5_xgjvZfLEle",
      "authorship_tag": "ABX9TyP12aCWuOWnQtS72j7/cwRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwojcik01/BSI-Mateusz-Wojcik/blob/master/CNN_2_klasy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieRJc7t-3j8e"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        " \n",
        " \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        " \n",
        "np.set_printoptions(precision=6, suppress=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig1M9ELy3oWj"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tcZybUL3qZC"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InfcEaTn3ql5"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/base_ddsm_cbm_2.zip\" -d \"./\" # wypakowanie plików z Drive"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaOtxRCR3qy0",
        "outputId": "cb300557-687d-47d5-b7f5-6fed2885a9c3"
      },
      "source": [
        "base_dir = './base_ddsm_cbm_2' # obliczanie ilości plików w każdym folderze\n",
        "raw_no_of_files = {}\n",
        "classes = ['ben_mal', 'nor']\n",
        "for dir in classes:\n",
        "    raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir, dir)))\n",
        "\n",
        "raw_no_of_files.items()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('ben_mal', 2003), ('nor', 9215)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfR1hOjK7rQ8"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPTwEFzC7u2V"
      },
      "source": [
        "data_dir = './images' # tworzenie katalogów: treningowego, walidacyjnego oraz testowego. \n",
        "                      #w każdym znajdują się 2 foldery: nor, ben_mal\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "valid_dir = os.path.join(data_dir, 'valid')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "train_nor_dir = os.path.join(train_dir, 'nor')\n",
        "train_ben_mal_dir = os.path.join(train_dir, 'ben_mal')\n",
        "\n",
        "valid_nor_dir = os.path.join(valid_dir, 'nor')\n",
        "valid_ben_mal_dir = os.path.join(valid_dir, 'ben_mal')\n",
        "\n",
        "test_nor_dir = os.path.join(test_dir, 'nor')\n",
        "test_ben_mal_dir = os.path.join(test_dir, 'ben_mal')\n",
        "\n",
        "for directory in (train_dir, valid_dir, test_dir):\n",
        "    if not os.path.exists(directory):\n",
        "        os.mkdir(directory)\n",
        "\n",
        "dirs = [train_nor_dir, train_ben_mal_dir, valid_nor_dir, valid_ben_mal_dir, test_nor_dir, test_ben_mal_dir]\n",
        "\n",
        "for dir in dirs:\n",
        "    if not os.path.exists(dir):\n",
        "        os.mkdir(dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge7c11XS8KDa"
      },
      "source": [
        "#kopiowanie\n",
        "nor_fnames = os.listdir(os.path.join(base_dir, 'nor'))\n",
        "ben_mal_fnames = os.listdir(os.path.join(base_dir, 'ben_mal'))\n",
        "\n",
        "\n",
        "nor_fnames = [fname for fname in nor_fnames if fname.split('.')[1].lower() in ['png']]\n",
        "ben_mal_fnames = [fname for fname in ben_mal_fnames if fname.split('.')[1].lower() in ['png']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__68Vwb68jLn"
      },
      "source": [
        "size = min(len(nor_fnames), len(ben_mal_fnames)) # ustalanie ilości plików w folderze \n",
        "\n",
        "train_size = int(np.floor(0.7 * size))\n",
        "valid_size = int(np.floor(0.2 * size))\n",
        "test_size = size - train_size - valid_size\n",
        "\n",
        "train_idx = train_size\n",
        "valid_idx = train_size + valid_size\n",
        "test_idx = train_size + valid_size + test_size"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL-rEKQk8qkQ"
      },
      "source": [
        "for i, fname in enumerate(nor_fnames): # proces kopiowania plików\n",
        "    if i <= train_idx:\n",
        "        src = os.path.join(base_dir, 'nor', fname)\n",
        "        dst = os.path.join(train_nor_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif train_idx < i <= valid_idx:\n",
        "        src = os.path.join(base_dir, 'nor', fname)\n",
        "        dst = os.path.join(valid_nor_dir, fname)\n",
        "        shutil.copyfile(src, dst) \n",
        "    elif valid_idx < i < test_idx:\n",
        "        src = os.path.join(base_dir, 'nor', fname)\n",
        "        dst = os.path.join(test_nor_dir, fname)\n",
        "        shutil.copyfile(src, dst) \n",
        "\n",
        "for i, fname in enumerate(ben_mal_fnames):\n",
        "    if i <= train_idx:\n",
        "        src = os.path.join(base_dir, 'ben_mal', fname)\n",
        "        dst = os.path.join(train_ben_mal_dir, fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "    elif train_idx < i <= valid_idx:\n",
        "        src = os.path.join(base_dir, 'ben_mal', fname)\n",
        "        dst = os.path.join(valid_ben_mal_dir, fname)\n",
        "        shutil.copyfile(src, dst) \n",
        "    elif valid_idx < i < test_idx:\n",
        "        src = os.path.join(base_dir, 'ben_mal', fname)\n",
        "        dst = os.path.join(test_ben_mal_dir, fname)\n",
        "        shutil.copyfile(src, dst)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGJJM7iE9pa5",
        "outputId": "3379d14f-df56-4713-cd4a-ce494f166560"
      },
      "source": [
        "# sprawdzanie ilości plików w folderach\n",
        "print('nor - trening', len(os.listdir(train_nor_dir))) \n",
        "print('nor - walidacja', len(os.listdir(valid_nor_dir)))\n",
        "print('nor - test', len(os.listdir(test_nor_dir)))\n",
        "\n",
        "print('ben_mal - trening', len(os.listdir(train_ben_mal_dir)))\n",
        "print('ben_mal - walidacja', len(os.listdir(valid_ben_mal_dir)))\n",
        "print('ben_mal - test', len(os.listdir(test_ben_mal_dir)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nor - trening 1403\n",
            "nor - walidacja 400\n",
            "nor - test 200\n",
            "ben_mal - trening 1403\n",
            "ben_mal - walidacja 400\n",
            "ben_mal - test 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7HB5MAcE4Rb",
        "outputId": "595a8df7-8268-4d26-b647-fd6eef6043cb"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# przeskalowanie obrazów o współczynnik 1/255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                   target_size=(128, 128),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir,\n",
        "                                                   target_size=(128, 128),\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode='binary')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2806 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFCKikTf-xd5",
        "outputId": "5dc3a05c-9afd-4700-a55c-7d2ea8a2d8bc"
      },
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(128, 128, 3)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "#        layers.Dropout(0.5),\n",
        "        layers.Dense(units=256, activation='relu'),\n",
        "        layers.Dense(units=1, activation='sigmoid') #1 sigmoid, 3 softmax\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 61, 61, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 655,905\n",
            "Trainable params: 655,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRWWz7RK-6s2"
      },
      "source": [
        "model.compile(optimizer='Adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnGZZmgzABjH"
      },
      "source": [
        "batch_size = 16\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = valid_size // batch_size\n",
        "\n",
        "#batch_size = 32\n",
        "#steps_per_epoch = train_size_ben_mal // batch_size\n",
        "#validation_steps = valid_size_ben_mal // batch_size"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1VUGIrtAH13",
        "outputId": "de4f88f2-1fe9-48ab-ac7d-99a1faed0b28"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=100, #steps_per_epoch\n",
        "                    epochs=40,    # 100\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=validation_steps\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " 58/100 [================>.............] - ETA: 0s - loss: 0.6924 - accuracy: 0.5122"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqaW3inZC4ie"
      },
      "source": [
        "def plot_hist(history):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['accuracy'], name='accuracy', mode='markers+lines'))\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_accuracy'], name='val_accuracy', mode='markers+lines'))\n",
        "    fig.update_layout(width=1000, height=500, title='Accuracy vs. Val Accuracy', xaxis_title='Epoki', yaxis_title='Accuracy', yaxis_type='log')\n",
        "    fig.show()\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['loss'], name='loss', mode='markers+lines'))\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_loss'], name='val_loss', mode='markers+lines'))\n",
        "    fig.update_layout(width=1000, height=500, title='Loss vs. Val Loss', xaxis_title='Epoki', yaxis_title='Loss', yaxis_type='log')\n",
        "    fig.show()\n",
        "\n",
        "plot_hist(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6GhvjFQFqrO"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                 target_size=(128, 128),\n",
        "                                                 batch_size=8,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
        "print('Dokładność testowania:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChoxJddlxxeY"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=1,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "y_prob = model.predict(test_generator, test_generator.samples)\n",
        "y_prob = y_prob.ravel()\n",
        "y_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt-Vyvyhx4Vv"
      },
      "source": [
        "predictions  = pd.DataFrame({'y_prob': y_prob})\n",
        "predictions['class'] = predictions['y_prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sduk9CoUx4h3"
      },
      "source": [
        "y_true = test_generator.classes\n",
        "y_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OS8WoA5x7Z2"
      },
      "source": [
        "y_pred = predictions['class'].values\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "livvksd9x4tO"
      },
      "source": [
        "test_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw4qiSOXyAbm"
      },
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R2PyWGvjL5h"
      },
      "source": [
        "def plot_confusion_matrix(cm):\n",
        "    cm = cm[::-1]\n",
        "    cm = pd.DataFrame(cm, columns=classes, index=classes[::-1])\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z=cm.values, x=list(cm.columns), y=list(cm.index), colorscale='ice', showscale=True, reversescale=True)\n",
        "    fig.update_layout(width=500, height=500, title='Confusion Matrix', font_size=16)\n",
        "    fig.show()\n",
        "\n",
        "import plotly.figure_factory as ff\n",
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}